{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.tri import Triangulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "DAYS_IN_SECONDS = 24 * 60 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryInterpolator:\n",
    "    delta_xy_avg = 5 # nominal average distance between points in x and y, 5 km\n",
    "    delta_z_avg = 5 # nominal average distance between points in z (1 day * 5 km / day)\n",
    "    s_avg = None\n",
    "    x_avg = None\n",
    "    y_avg = None\n",
    "    z_avg = None\n",
    "    date_0 = None\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\" Set parameters \"\"\"\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "    def fit(self, df):\n",
    "        self.read_trajectories(df)\n",
    "        self.normalize_coordinates()\n",
    "        self.prepare_train_data()\n",
    "        self.train_interpolators()\n",
    "\n",
    "    def read_trajectories(self, df):\n",
    "        self.date_0 = pd.Timestamp(df.d.min())\n",
    "        self.traj_x = [] # km\n",
    "        self.traj_y = [] # km\n",
    "        self.traj_t = [] # days\n",
    "        self.traj_u = [] # km / day\n",
    "        self.traj_v = [] # km / day\n",
    "        self.traj_s = [] # km / day\n",
    "        for _, g in df.groupby('g'):\n",
    "            g_sorted = g.sort_values('d')\n",
    "            g_days = (g.d - self.date_0).dt.total_seconds() / DAYS_IN_SECONDS\n",
    "            self.traj_x.append(g_sorted.x.values / 1e3)\n",
    "            self.traj_y.append(g_sorted.y.values / 1e3)\n",
    "            self.traj_t.append(g_days.values)\n",
    "            u = np.diff(g_sorted.x.values) / 1e3 / np.diff(g_days.values)\n",
    "            v = np.diff(g_sorted.y.values) / 1e3 / np.diff(g_days.values)\n",
    "            s = np.hypot(u, v)\n",
    "            self.traj_u.append(u)\n",
    "            self.traj_v.append(v)\n",
    "            self.traj_s.append(s)\n",
    "\n",
    "    def normalize_coordinates(self):\n",
    "        self.s_avg = np.mean(np.hstack(self.traj_s))\n",
    "        self.x_avg = np.mean(np.hstack(self.traj_x))\n",
    "        self.y_avg = np.mean(np.hstack(self.traj_y))\n",
    "\n",
    "        traj_z = [t * self.s_avg for t in self.traj_t]  # time coordinate expressed in km\n",
    "        self.z_avg = np.mean(np.hstack(traj_z))\n",
    "\n",
    "        self.traj_xn = [(x - self.x_avg) / self.delta_xy_avg for x in self.traj_x]\n",
    "        self.traj_yn = [(y - self.y_avg) / self.delta_xy_avg for y in self.traj_y]\n",
    "        self.traj_zn = [(z - self.z_avg) / self.delta_z_avg for z in traj_z]\n",
    "        self.traj_un = [u * self.delta_z_avg / self.s_avg / self.delta_xy_avg for u in self.traj_u]\n",
    "        self.traj_vn = [v * self.delta_z_avg / self.s_avg / self.delta_xy_avg for v in self.traj_v]\n",
    "\n",
    "    def prepare_train_data(self):\n",
    "        inputs = np.column_stack([\n",
    "            np.hstack([i[:-1] for i in self.traj_xn]),\n",
    "            np.hstack([i[:-1] for i in self.traj_yn]),\n",
    "            np.hstack([i[:-1] for i in self.traj_zn]),\n",
    "        ])\n",
    "        targets_u = np.hstack([i for i in self.traj_un])\n",
    "        targets_v = np.hstack([i for i in self.traj_vn])\n",
    "\n",
    "        # Split the data into training and testing sets (80% train, 20% test)\n",
    "        self.X_train, self.X_test, self.y_u_train, self.y_u_test, self.y_v_train, self.y_v_test = train_test_split(\n",
    "            inputs, targets_u, targets_v, test_size=0.1)\n",
    "\n",
    "    def train_interpolators(self):\n",
    "        self.lndi_u = LinearNDInterpolator(self.X_train, self.y_u_train, rescale=True)\n",
    "        self.lndi_v = LinearNDInterpolator(self.X_train, self.y_v_train, rescale=True)\n",
    "        y_u_test_pred = self.lndi_u(self.X_test)\n",
    "        y_v_test_pred = self.lndi_v(self.X_test)\n",
    "\n",
    "        self.mean_squared_error = mean_squared_error(\n",
    "            self.y_u_test[np.isfinite(y_u_test_pred)],\n",
    "            y_u_test_pred[np.isfinite(y_u_test_pred)])\n",
    "        self.r2_score = r2_score(\n",
    "                  self.y_u_test[np.isfinite(y_u_test_pred)],\n",
    "                  y_u_test_pred[np.isfinite(y_u_test_pred)])\n",
    "        # Compute metrics\n",
    "        print(\"Mean Squared Error:\", self.mean_squared_error)\n",
    "        print(\"R^2 Score:\", self.r2_score)\n",
    "\n",
    "    def normalize_start_coordinates(self, x0, y0, t0, t1, delta_t):\n",
    "        x0n = (x0 / 1e3 - self.x_avg) / self.delta_xy_avg\n",
    "        y0n = (y0 / 1e3 - self.y_avg) / self.delta_xy_avg\n",
    "        t0_days = (t0 - self.date_0).total_seconds() / DAYS_IN_SECONDS\n",
    "        z0 = t0_days * self.s_avg\n",
    "        z0n = (z0 - self.z_avg) / self.delta_z_avg\n",
    "\n",
    "        t1_days = (t1 - self.date_0).total_seconds() / DAYS_IN_SECONDS\n",
    "        z1 = t1_days * self.s_avg\n",
    "        z1n = (z1 - self.z_avg) / self.delta_z_avg\n",
    "\n",
    "        delta_zn = delta_t.seconds / DAYS_IN_SECONDS * self.s_avg / self.delta_z_avg\n",
    "\n",
    "        z0n = np.full(x0.shape, z0n)\n",
    "        return x0n, y0n, z0n, z1n, delta_zn\n",
    "\n",
    "    def grow_trajectories(self, x0n, y0n, z0n, z1n, dzn):\n",
    "        traj_i_x = []\n",
    "        traj_i_y = []\n",
    "        traj_i_z = []\n",
    "        time_len = int((z1n - z0n[0] + dzn) / dzn)\n",
    "        for i in range(time_len):\n",
    "            traj_i_x.append(x0n.copy())\n",
    "            traj_i_y.append(y0n.copy())\n",
    "            traj_i_z.append(z0n.copy())\n",
    "            inputs0 =  np.column_stack([x0n, y0n, z0n])\n",
    "            u_pred = self.lndi_u(inputs0)\n",
    "            v_pred = self.lndi_v(inputs0)\n",
    "            u_pred_norm = dzn * u_pred\n",
    "            v_pred_norm = dzn * v_pred\n",
    "\n",
    "            x0n += u_pred_norm\n",
    "            y0n += v_pred_norm\n",
    "            z0n += dzn\n",
    "        traj_i_x, traj_i_y, traj_i_z = list(map(np.array, (traj_i_x, traj_i_y, traj_i_z)))        \n",
    "        return traj_i_x, traj_i_y, traj_i_z\n",
    "\n",
    "    def back2si(self, traj_i_x, traj_i_y, time_start, time_stop, time_step):\n",
    "        traj_x = 1e3 * (traj_i_x * self.delta_xy_avg + self.x_avg)\n",
    "        traj_y = 1e3 * (traj_i_y * self.delta_xy_avg + self.y_avg)\n",
    "        traj_t = pd.date_range(time_start, time_stop, freq=time_step).to_series()\n",
    "        return traj_x, traj_y, traj_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read feather file and convert to a DataFrame usable by pysida\n",
    "feather_file = 'points.feather'\n",
    "#points = pd.read_feather(feather_file)\n",
    "#df = points[['image_id', 'trajectory_id', 'time', 'x', 'y', 'corr']].copy().rename(columns={'image_id':'i', 'trajectory_id': 'g', 'time':'d', 'x':'x', 'y':'y', 'corr':'q'})\n",
    "df = pd.read_feather(feather_file)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all points between two days\n",
    "sub_df0 = df[(df.d > datetime(2020, 1, 15)) & (df.d < datetime(2020, 1, 16))]\n",
    "\n",
    "radius = 1e5\n",
    "\n",
    "center_x = 0.5e6\n",
    "center_y = -0.5e6\n",
    "\n",
    "#center_x = 0\n",
    "#center_y = -0.6e6\n",
    "\n",
    "#center_x = 0.6e6\n",
    "#center_y = 0\n",
    "\n",
    "dist = np.hypot(sub_df0.x - center_x, sub_df0.y - center_y) < radius\n",
    "plt.scatter(sub_df0.x, sub_df0.y, c=dist, s=0.1, alpha=0.1)\n",
    "plt.colorbar()\n",
    "end_point_g = sub_df0[dist].g.unique()\n",
    "print(sub_df0.shape, sub_df0.g.unique().size, end_point_g.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[(df.d > datetime(2020, 1, 1)) & (df.d < datetime(2020, 1, 21))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select ONLY with end of trajectroies in these two days\n",
    "disk_df = sub_df[sub_df['g'].isin(end_point_g)]\n",
    "print(disk_df.shape, disk_df.g.unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = TrajectoryInterpolator()\n",
    "ti.fit(disk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(np.hstack(ti.traj_xn), bins=50)\n",
    "_ = plt.hist(np.hstack(ti.traj_yn), bins=50, alpha=0.5)\n",
    "_ = plt.hist(np.hstack(ti.traj_zn), bins=50, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "_ = plt.hist(np.hstack(ti.traj_un), bins=50)\n",
    "_ = plt.hist(np.hstack(ti.traj_vn), bins=50, alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "for x, y, z in zip(ti.traj_xn, ti.traj_yn, ti.traj_zn):\n",
    "    plt.plot(z, y, 'k.-', alpha=0.1)\n",
    "plt.xticks(np.arange(-24, 18, 1))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initial points for interpolation\n",
    "time_start = pd.Timestamp('2020-01-03')\n",
    "time_stop = pd.Timestamp('2020-01-20')\n",
    "time_step = pd.Timedelta('6H')\n",
    "\n",
    "x0df = disk_df.x\n",
    "y0df = disk_df.y\n",
    "\n",
    "res = 10000\n",
    "x0lim = np.percentile(x0df, [1,99]) + np.array([0, res])\n",
    "y0lim = np.percentile(y0df, [1,99]) + np.array([0, res])\n",
    "\n",
    "x0grd, y0grd = np.meshgrid(np.arange(*x0lim, res), np.arange(*y0lim, res))\n",
    "x0, y0 = x0grd.flatten(), y0grd.flatten()\n",
    "\n",
    "plt.plot(x0df, y0df, '.', alpha=0.1)\n",
    "plt.plot(x0, y0, '.')\n",
    "\n",
    "\n",
    "x0n, y0n, z0n, z1n, dzn = ti.normalize_start_coordinates(x0, y0, time_start, time_stop, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_ixn, traj_iyn, traj_izn = ti.grow_trajectories(x0n, y0n, z0n, z1n, dzn)\n",
    "traj_x, traj_y, traj_t = ti.back2si(traj_ixn, traj_iyn, time_start, time_stop, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, g in disk_df.groupby('g'):\n",
    "    g_sorted = g.sort_values('d')\n",
    "    plt.plot(g_sorted.d, g_sorted.x, 'k.-', alpha=0.1)\n",
    "\n",
    "for x in traj_x.T:\n",
    "    plt.plot(traj_t, x, 'r.-', alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find finite starting points and triangulate\n",
    "gpi = np.isfinite(traj_x[0])\n",
    "t0 = Triangulation(traj_x[0, gpi], traj_y[0, gpi])\n",
    "\n",
    "margin = 20000\n",
    "xlim = np.nanpercentile(traj_x, [0, 100]) + np.array([-margin , margin])\n",
    "ylim = np.nanpercentile(traj_y, [0, 100]) + np.array([-margin , margin])\n",
    "\n",
    "# plot the advected triangulation\n",
    "fig, axs = plt.subplots(1, 1, figsize=(10, 10))\n",
    "plt.triplot(t0, color='gray', alpha=0.2)\n",
    "for i in range(len(traj_x)):\n",
    "    plt.plot(traj_x[i, gpi], traj_y[i, gpi], 'k.', alpha=0.1)\n",
    "    trp = plt.triplot(traj_x[i, gpi], traj_y[i, gpi], t0.triangles, color='blue')\n",
    "    axs.set_aspect('equal')\n",
    "    axs.set_xlim(xlim)\n",
    "    axs.set_ylim(ylim)\n",
    "    plt.savefig(f'triangulation_step_{i:03d}.png', dpi=150)\n",
    "    trp[0].remove()\n",
    "    fig.canvas.draw()\n",
    "    #plt.show()\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Get all PNG files matching the pattern\n",
    "png_files = sorted(glob.glob('triangulation_step_*.png'))\n",
    "\n",
    "# Create list to store images\n",
    "images = []\n",
    "\n",
    "# Load all images\n",
    "for file in png_files:\n",
    "    img = Image.open(file)\n",
    "    images.append(img)\n",
    "\n",
    "# Save as GIF animation\n",
    "if images:\n",
    "    images[0].save('triangulation_animation.gif', \n",
    "                   save_all=True, \n",
    "                   append_images=images[1:], \n",
    "                   duration=200,  # milliseconds per frame\n",
    "                   loop=0)  # infinite loop\n",
    "    print(f\"Created GIF animation with {len(images)} frames\")\n",
    "else:\n",
    "    print(\"No PNG files found matching pattern 'triangulation_step_*.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
